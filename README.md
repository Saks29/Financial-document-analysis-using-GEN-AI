# ğŸ“Š Document Analyzer & Assistant |ğŸ§¾âš¡GEN-AI using RAG+LangChain

<div align="center">

<img width="1882" height="819" alt="Screenshot 2025-09-09 011433" src="https://github.com/user-attachments/assets/b0d65699-d5ec-4990-86cb-a1b2de489693" />

**ğŸ›¡ï¸ Privacy-First â€¢ ğŸ¤– AI-Powered â€¢ ğŸ’» Completely Offline**

<img width="1853" height="824" alt="Screenshot 2025-09-09 011703" src="https://github.com/user-attachments/assets/6e1f652c-b26f-47ca-8be8-ae0fe7e92de9" />
<img width="1889" height="822" alt="Screenshot 2025-09-09 012132" src="https://github.com/user-attachments/assets/3d0b4773-ab6d-4060-bef2-062aba182e0e" />
<img width="1898" height="830" alt="Screenshot 2025-09-09 012221" src="https://github.com/user-attachments/assets/89eb628d-5c40-4d08-8641-d48b1f70c87e" />

*Transform your document analysis workflow with AI-powered insights while keeping your data completely secure and offline.*

[ğŸš€ Quick Start](#quick-start) â€¢ [ğŸ“– Documentation](#features) â€¢ [ğŸ¯ Use Cases](#use-cases) â€¢ [ğŸ¤ Contributing](#contributing)

</div>

---

## ğŸŒŸ Why This Project?

In today's data-driven world, document analysis is crucial, but **privacy shouldn't be compromised**. This tool provides enterprise-grade document intelligence while ensuring your sensitive files never leave your local machine.

### ğŸ¯ Perfect For:
- ğŸ’¼ **Financial Professionals** - Analyze reports, statements, and financial documents
- ğŸ“ **Researchers & Students** - Extract insights from academic papers and studies  
- ğŸ‘¥ **HR Teams** - Screen resumes and candidate profiles intelligently
- âš–ï¸ **Legal Professionals** - Review contracts and legal documents
- ğŸ¢ **Business Analysts** - Process corporate documents and presentations

---

## âœ¨ Features

### ğŸ”’ **Privacy-First Architecture**
- **100% Offline Processing** - Your documents never leave your machine
- **Local AI Models** - Powered by Ollama for complete data control
- **Secure Vector Storage** - Documents processed and stored locally

### ğŸ§  **Intelligent Analysis**
- **Natural Language Queries** - Ask questions in plain English
- **Contextual Understanding** - AI comprehends document context and nuances
- **Multi-format Support** - PDF documents up to 200MB
- **Semantic Search** - Advanced vector-based document retrieval

### âš¡ **Performance & Usability**
- **Fast Processing** - Quick document ingestion and analysis
- **Interactive Interface** - Clean, intuitive web-based UI
- **Real-time Responses** - Instant answers to your queries
- **Session Memory** - Maintains conversation context

---

## ğŸ–¥ï¸ Screenshots

<div align="center">

### Document Upload Interface
![Upload Interface](https://via.placeholder.com/600x300/2d3748/ffffff?text=Clean+Upload+Interface)

### AI-Powered Analysis
![Analysis Demo](https://via.placeholder.com/600x300/2d3748/ffffff?text=Intelligent+Document+Analysis)

### Question-Answer Interface  
![Q&A Interface](https://via.placeholder.com/600x300/2d3748/ffffff?text=Natural+Language+Q%26A)

</div>

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8 or higher
- 4GB+ RAM (recommended for optimal performance)
- Ollama installed locally

## ğŸ“‹ Usage

### Step 1: Upload Document
- Drag and drop your PDF file (max 200MB)
- Wait for processing completion

### Step 2: Ask Questions
- Type natural language questions about your document
- Examples:
  - *"What is the main conclusion of this research?"*
  - *"Which job roles match my skills from this resume?"*
  - *"What are the key financial metrics mentioned?"*

### Step 3: Get Intelligent Answers
- Receive contextual, accurate responses
- Ask follow-up questions for deeper analysis

---

## ğŸ¯ Use Cases

### Resume Analysis
```
Question: "Which IT job role is best suited for me?"
Answer: Based on your B.Tech in Information Technology, 8.38 CGPA, 
and expertise in data science, analytics, and machine learning, 
you're well-suited for roles like Data Scientist, Business 
Intelligence Analyst, or AI-related positions.
```

### Financial Document Review
```
Question: "What is the company's revenue growth trend?"
Answer: [Analyzes financial statements and provides insights 
on revenue patterns, growth rates, and key performance indicators]
```

### Research Paper Analysis
```
Question: "What are the main research methodologies used?"
Answer: [Identifies and explains research methods, sample sizes, 
and analytical approaches used in the study]
```

---

## ğŸ› ï¸ Technical Architecture

```mermaid
graph LR
    A[PDF Upload] --> B[Document Processing]
    B --> C[Text Extraction]
    C --> D[Chunking & Embedding]
    D --> E[Vector Database Storage]
    E --> F[User Query]
    F --> G[Semantic Search]
    G --> H[Context Retrieval]
    H --> I[AI Response Generation]
    I --> J[Natural Language Answer]
```

### Tech Stack
- **Frontend**: Streamlit (Interactive Web Interface)
- **Backend**: Python, LangChain (Document Processing & AI Orchestration)
- **AI Engine**: Ollama (Local LLM Hosting)
- **Vector DB**: ChromaDB/FAISS (Semantic Search)
- **Document Processing**: PyPDF2, LangChain Document Loaders

---

## ğŸ“ Project Structure

```
document-analyzer-assistant/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ document_processor.py  # PDF processing logic
â”‚   â”œâ”€â”€ vector_store.py        # Vector database operations
â”‚   â”œâ”€â”€ ai_assistant.py        # AI query processing
â”‚   â””â”€â”€ utils.py              # Utility functions
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py       # Configuration settings
â”œâ”€â”€ data/                 # Local document storage (gitignored)
â”œâ”€â”€ tests/               # Unit tests
â”œâ”€â”€ docs/                # Documentation
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration & Customization

### Environment Setup
```bash
# .env file configuration
OLLAMA_BASE_URL=http://localhost:11434
MODEL_NAME=llama2                    # Options: llama2, mistral, codellama
VECTOR_DB_PATH=./data/vectordb
MAX_FILE_SIZE=200                    # Maximum file size in MB
CHUNK_SIZE=1000                      # Text chunk size for processing
CHUNK_OVERLAP=200                    # Overlap between chunks
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

### Model Recommendations

| Model | Use Case | Speed | Accuracy | RAM Required |
|-------|----------|-------|----------|--------------|
| `llama2:7b` | General documents | â­â­â­ | â­â­â­â­ | 8GB |
| `mistral:7b` | Fast processing | â­â­â­â­ | â­â­â­ | 6GB |
| `codellama:7b` | Technical docs | â­â­ | â­â­â­â­â­ | 8GB |
| `phi:2.7b` | Resource-constrained | â­â­â­â­â­ | â­â­ | 4GB |

### Performance Optimization
- **Batch Processing**: Process multiple documents simultaneously
- **Caching**: Store embeddings for faster re-querying
- **Memory Management**: Automatic cleanup of unused vectors
- **GPU Acceleration**: Optional CUDA support for faster processing

---

## ğŸ¤ Contributing

I welcome contributions! 

### Ways to Contribute:
- ğŸ› **Bug Reports** - Help us identify and fix issues
- âœ¨ **Feature Requests** - Suggest new capabilities
- ğŸ“ **Documentation** - Improve guides and examples
- ğŸ§ª **Testing** - Add test cases and improve coverage
- ğŸ’» **Code** - Submit pull requests for enhancements
